---
title: Categorical Feature Compression via Submodular Optimization
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/bateni19a/bateni19a.pdf
url: http://proceedings.mlr.press/v97/bateni19a.html
abstract: In the era of big data, learning from categorical features with very large
  vocabularies (e.g., 28 million for the Criteo click prediction dataset) has become
  a practical challenge for machine learning researchers and practitioners. We design
  a highly-scalable vocabulary compression algorithm that seeks to maximize the mutual
  information between the compressed categorical feature and the target binary labels
  and we furthermore show that its solution is guaranteed to be within a $1-1/e \approx
  63%$ factor of the global optimal solution. Although in some settings, entropy-based
  set functions are known to be submodular, this is not the case for the mutual information
  objective we consider (mutual information with respect to the target labels). To
  address this, we introduce a novel re-parametrization of the mutual information
  objective, which we prove is submodular, and also design a data structure to query
  the submodular function in amortized $O(\log n )$ time (where $n$ is the input vocabulary
  size). Our complete algorithm is shown to operate in $O(n \log n )$ time. Additionally,
  we design a distributed implementation in which the query data structure is decomposed
  across $O(k)$ machines such that each machine only requires $O(\frac n k)$ space,
  while still preserving the approximation guarantee and using only logarithmic rounds
  of computation. We also provide analysis of simple alternative heuristic compression
  methods to demonstrate they cannot achieve any approximation guarantee. Using the
  large-scale Criteo learning task, we demonstrate better performance in retaining
  mutual information and also verify competitive learning performance compared to
  other baseline methods.
layout: inproceedings
id: bateni19a
tex_title: Categorical Feature Compression via Submodular Optimization
firstpage: 515
lastpage: 523
page: 515-523
order: 515
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Bateni, Mohammadhossein and Chen, Lin and Esfandiari, Hossein and Fu,
  Thomas and Mirrokni, Vahab and Rostamizadeh, Afshin
author:
- given: Mohammadhossein
  family: Bateni
- given: Lin
  family: Chen
- given: Hossein
  family: Esfandiari
- given: Thomas
  family: Fu
- given: Vahab
  family: Mirrokni
- given: Afshin
  family: Rostamizadeh
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/bateni19a/bateni19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
