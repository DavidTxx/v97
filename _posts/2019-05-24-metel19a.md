---
title: Simple Stochastic Gradient Methods for Non-Smooth Non-Convex Regularized Optimization
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/metel19a/metel19a.pdf
url: http://proceedings.mlr.press/v97/metel19a.html
abstract: Our work focuses on stochastic gradient methods for optimizing a smooth
  non-convex loss function with a non-smooth non-convex regularizer. Research on this
  class of problem is quite limited, and until recently no non-asymptotic convergence
  results have been reported. We present two simple stochastic gradient algorithms,
  for finite-sum and general stochastic optimization problems, which have superior
  convergence complexities compared to the current state-of-the-art. We also compare
  our algorithmsâ€™ performance in practice for empirical risk minimization.
layout: inproceedings
id: metel19a
tex_title: Simple Stochastic Gradient Methods for Non-Smooth Non-Convex Regularized
  Optimization
firstpage: 4537
lastpage: 4545
page: 4537-4545
order: 4537
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Metel, Michael and Takeda, Akiko
author:
- given: Michael
  family: Metel
- given: Akiko
  family: Takeda
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/metel19a/metel19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
