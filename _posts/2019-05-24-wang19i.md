---
title: On the Convergence and Robustness of Adversarial Training
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/wang19i/wang19i.pdf
url: http://proceedings.mlr.press/v97/wang19i.html
abstract: Improving the robustness of deep neural networks (DNNs) to adversarial examples
  is an important yet challenging problem for secure deep learning. Across existing
  defense techniques, adversarial training with Projected Gradient Decent (PGD) is
  amongst the most effective. Adversarial training solves a min-max optimization problem,
  with the <em>inner maximization</em> generating adversarial examples by maximizing
  the classification loss, and the <em>outer minimization</em> finding model parameters
  by minimizing the loss on adversarial examples generated from the inner maximization.
  A criterion that measures how well the inner maximization is solved is therefore
  crucial for adversarial training. In this paper, we propose such a criterion, namely
  First-Order Stationary Condition for constrained optimization (FOSC), to quantitatively
  evaluate the convergence quality of adversarial examples found in the inner maximization.
  With FOSC, we find that to ensure better robustness, it is essential to use adversarial
  examples with better convergence quality at the <em>later stages</em> of training.
  Yet at the early stages, high convergence quality adversarial examples are not necessary
  and may even lead to poor robustness. Based on these observations, we propose a
  <em>dynamic</em> training strategy to gradually increase the convergence quality
  of the generated adversarial examples, which significantly improves the robustness
  of adversarial training. Our theoretical and empirical results show the effectiveness
  of the proposed method.
layout: inproceedings
id: wang19i
tex_title: On the Convergence and Robustness of Adversarial Training
firstpage: 6586
lastpage: 6595
page: 6586-6595
order: 6586
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Wang, Yisen and Ma, Xingjun and Bailey, James and Yi, Jinfeng and Zhou,
  Bowen and Gu, Quanquan
author:
- given: Yisen
  family: Wang
- given: Xingjun
  family: Ma
- given: James
  family: Bailey
- given: Jinfeng
  family: Yi
- given: Bowen
  family: Zhou
- given: Quanquan
  family: Gu
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/wang19i/wang19i-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
