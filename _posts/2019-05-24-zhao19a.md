---
title: On Learning Invariant Representations for Domain Adaptation
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/zhao19a/zhao19a.pdf
url: http://proceedings.mlr.press/v97/zhao19a.html
abstract: 'Due to the ability of deep neural nets to learn rich representations, recent
  advances in unsupervised domain adaptation have focused on learning domain-invariant
  features that achieve a small error on the source domain. The hope is that the learnt
  representation, together with the hypothesis learnt from the source domain, can
  generalize to the target domain. In this paper, we first construct a simple counterexample
  showing that, contrary to common belief, the above conditions are not sufficient
  to guarantee successful domain adaptation. In particular, the counterexample exhibits
  <em>conditional shift</em>: the class-conditional distributions of input features
  change between source and target domains. To give a sufficient condition for domain
  adaptation, we propose a natural and interpretable generalization upper bound that
  explicitly takes into account the aforementioned shift. Moreover, we shed new light
  on the problem by proving an information-theoretic lower bound on the joint error
  of <em>any</em> domain adaptation method that attempts to learn invariant representations.
  Our result characterizes a fundamental tradeoff between learning invariant representations
  and achieving small joint error on both domains when the marginal label distributions
  differ from source to target. Finally, we conduct experiments on real-world datasets
  that corroborate our theoretical findings. We believe these insights are helpful
  in guiding the future design of domain adaptation and representation learning algorithms.'
layout: inproceedings
id: zhao19a
tex_title: On Learning Invariant Representations for Domain Adaptation
firstpage: 7523
lastpage: 7532
page: 7523-7532
order: 7523
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Zhao, Han and Combes, Remi Tachet Des and Zhang, Kun and Gordon, Geoffrey
author:
- given: Han
  family: Zhao
- given: Remi Tachet Des
  family: Combes
- given: Kun
  family: Zhang
- given: Geoffrey
  family: Gordon
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/zhao19a/zhao19a-supp.pdf
- label: Code
  link: https://github.com/KeiraZhao/On-Learning-Invariant-Representations-for-Domain-Adaptation.git
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
