---
title: Analyzing Federated Learning through an Adversarial Lens
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/bhagoji19a/bhagoji19a.pdf
url: http://proceedings.mlr.press/v97/bhagoji19a.html
abstract: Federated learning distributes model training among a multitude of agents,
  who, guided by privacy concerns, perform training using their local data but share
  only model parameter updates, for iterative aggregation at the server to train an
  overall global model. In this work, we explore how the federated learning setting
  gives rise to a new threat, namely model poisoning, which differs from traditional
  data poisoning. Model poisoning is carried out by an adversary controlling a small
  number of malicious agents (usually 1) with the aim of causing the global model
  to misclassify a set of chosen inputs with high conﬁdence. We explore a number of
  strategies to carry out this attack on deep neural networks, starting with targeted
  model poisoning using a simple boosting of the malicious agent’s update to overcome
  the effects of other agents. We also propose two critical notions of stealth to
  detect malicious updates. We bypass these by including them in the adversarial objective
  to carry out stealthy model poisoning. We improve its stealth with the use of an
  alternating minimization strategy which alternately optimizes for stealth and the
  adversarial objective. We also empirically demonstrate that Byzantine-resilient
  aggregation strategies are not robust to our attacks. Our results indicate that
  highly constrained adversaries can carry out model poisoning attacks while maintaining
  stealth, thus highlighting the vulnerability of the federated learning setting and
  the need to develop effective defense strategies.
layout: inproceedings
id: bhagoji19a
tex_title: Analyzing Federated Learning through an Adversarial Lens
firstpage: 634
lastpage: 643
page: 634-643
order: 634
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Bhagoji, Arjun Nitin and Chakraborty, Supriyo and Mittal, Prateek and
  Calo, Seraphin
author:
- given: Arjun Nitin
  family: Bhagoji
- given: Supriyo
  family: Chakraborty
- given: Prateek
  family: Mittal
- given: Seraphin
  family: Calo
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/bhagoji19a/bhagoji19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
