---
title: Distributed Learning over Unreliable Networks
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/yu19f/yu19f.pdf
url: http://proceedings.mlr.press/v97/yu19f.html
abstract: 'Most of today’s distributed machine learning systems assume <em>reliable
  networks</em>: whenever two machines exchange information (e.g., gradients or models),
  the network should guarantee the delivery of the message. At the same time, recent
  work exhibits the impressive tolerance of machine learning algorithms to errors
  or noise arising from relaxed communication or synchronization. In this paper, we
  connect these two trends, and consider the following question: <em>Can we design
  machine learning systems that are tolerant to network unreliability during training?</em>
  With this motivation, we focus on a theoretical problem of independent interest—given
  a standard distributed parameter server architecture, if every communication between
  the worker and the server has a non-zero probability $p$ of being dropped, does
  there exist an algorithm that still converges, and at what speed? In the context
  of prior art, this problem can be phrased as <em>distributed learning over random
  topologies</em>. The technical contribution of this paper is a novel theoretical
  analysis proving that distributed learning over random topologies can achieve comparable
  convergence rate to centralized or distributed learning over reliable networks.
  Further, we prove that the influence of the packet drop rate diminishes with the
  growth of the number of parameter servers. We map this theoretical result onto a
  real-world scenario, training deep neural networks over an unreliable network layer,
  and conduct network simulation to validate the system improvement by allowing the
  networks to be unreliable.'
layout: inproceedings
id: yu19f
tex_title: Distributed Learning over Unreliable Networks
firstpage: 7202
lastpage: 7212
page: 7202-7212
order: 7202
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Yu, Chen and Tang, Hanlin and Renggli, Cedric and Kassing, Simon and
  Singla, Ankit and Alistarh, Dan and Zhang, Ce and Liu, Ji
author:
- given: Chen
  family: Yu
- given: Hanlin
  family: Tang
- given: Cedric
  family: Renggli
- given: Simon
  family: Kassing
- given: Ankit
  family: Singla
- given: Dan
  family: Alistarh
- given: Ce
  family: Zhang
- given: Ji
  family: Liu
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/yu19f/yu19f-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
