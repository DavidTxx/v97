---
title: Rademacher Complexity for Adversarially Robust Generalization
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/yin19b/yin19b.pdf
url: http://proceedings.mlr.press/v97/yin19b.html
abstract: Many machine learning models are vulnerable to adversarial attacks; for
  example, adding adversarial perturbations that are imperceptible to humans can often
  make machine learning models produce wrong predictions with high confidence; moreover,
  although we may obtain robust models on the training dataset via adversarial training,
  in some problems the learned models cannot generalize well to the test data. In
  this paper, we focus on $\ell_\infty$ attacks, and study the adversarially robust
  generalization problem through the lens of Rademacher complexity. For binary linear
  classifiers, we prove tight bounds for the adversarial Rademacher complexity, and
  show that the adversarial Rademacher complexity is never smaller than its natural
  counterpart, and it has an unavoidable dimension dependence, unless the weight vector
  has bounded $\ell_1$ norm, and our results also extend to multi-class linear classifiers;
  in addition, for (nonlinear) neural networks, we show that the dimension dependence
  in the adversarial Rademacher complexity also exists. We further consider a surrogate
  adversarial loss for one-hidden layer ReLU network and prove margin bounds for this
  setting. Our results indicate that having $\ell_1$ norm constraints on the weight
  matrices might be a potential way to improve generalization in the adversarial setting.
  We demonstrate experimental results that validate our theoretical findings.
layout: inproceedings
id: yin19b
tex_title: Rademacher Complexity for Adversarially Robust Generalization
firstpage: 7085
lastpage: 7094
page: 7085-7094
order: 7085
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Yin, Dong and Kannan, Ramchandran and Bartlett, Peter
author:
- given: Dong
  family: Yin
- given: Ramchandran
  family: Kannan
- given: Peter
  family: Bartlett
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/yin19b/yin19b-supp.pdf
- label: Code
  link: https://github.com/dongyin92/adversarially-robust-generalization
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
