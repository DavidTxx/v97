---
title: Online Convex Optimization in Adversarial Markov Decision Processes
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/rosenberg19a/rosenberg19a.pdf
url: http://proceedings.mlr.press/v97/rosenberg19a.html
abstract: We consider online learning in episodic loop-free Markov decision processes
  (MDPs), where the loss function can change arbitrarily between episodes, and the
  transition function is not known to the learner. We show $\tilde{O}(L|X|\sqrt{|A|T})$
  regret bound, where $T$ is the number of episodes, $X$ is the state space, $A$ is
  the action space, and $L$ is the length of each episode. Our online algorithm is
  implemented using entropic regularization methodology, which allows to extend the
  original adversarial MDP model to handle convex performance criteria (different
  ways to aggregate the losses of a single episode) , as well as improve previous
  regret bounds.
layout: inproceedings
id: rosenberg19a
tex_title: Online Convex Optimization in Adversarial {M}arkov Decision Processes
firstpage: 5478
lastpage: 5486
page: 5478-5486
order: 5478
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Rosenberg, Aviv and Mansour, Yishay
author:
- given: Aviv
  family: Rosenberg
- given: Yishay
  family: Mansour
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/rosenberg19a/rosenberg19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
