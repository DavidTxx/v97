---
title: Distributional Reinforcement Learning for Efficient Exploration
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/mavrin19a/mavrin19a.pdf
url: http://proceedings.mlr.press/v97/mavrin19a.html
abstract: In distributional reinforcement learning (RL), the estimated distribution
  of value functions model both the parametric and intrinsic uncertainties. We propose
  a novel and efficient exploration method for deep RL that has two components. The
  first is a decaying schedule to suppress the intrinsic uncertainty. The second is
  an exploration bonus calculated from the upper quantiles of the learned distribution.
  In Atari 2600 games, our method achieves 483 % average gain across 49 games in cumulative
  rewards over QR-DQN. We also compared our algorithm with QR-DQN in a challenging
  3D driving simulator (CARLA). Results show that our algorithm achieves nearoptimal
  safety rewards twice faster than QRDQN.
layout: inproceedings
id: mavrin19a
tex_title: Distributional Reinforcement Learning for Efficient Exploration
firstpage: 4424
lastpage: 4434
page: 4424-4434
order: 4424
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Mavrin, Borislav and Yao, Hengshuai and Kong, Linglong and Wu, Kaiwen
  and Yu, Yaoliang
author:
- given: Borislav
  family: Mavrin
- given: Hengshuai
  family: Yao
- given: Linglong
  family: Kong
- given: Kaiwen
  family: Wu
- given: Yaoliang
  family: Yu
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
