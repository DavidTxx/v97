---
title: Semi-Cyclic Stochastic Gradient Descent
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/eichner19a/eichner19a.pdf
url: http://proceedings.mlr.press/v97/eichner19a.html
abstract: We consider convex SGD updates with a block-cyclic structure, i.e., where
  each cycle consists of a small number of blocks, each with many samples from a possibly
  different, block-specific, distribution. This situation arises, e.g., in Federated
  Learning where the mobile devices available for updates at different times during
  the day have different characteristics. We show that such block-cyclic structure
  can significantly deteriorate the performance of SGD, but propose a simple approach
  that allows prediction with the same guarantees as for i.i.d., non-cyclic, sampling.
layout: inproceedings
id: eichner19a
tex_title: Semi-Cyclic Stochastic Gradient Descent
firstpage: 1764
lastpage: 1773
page: 1764-1773
order: 1764
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Eichner, Hubert and Koren, Tomer and Mcmahan, Brendan and Srebro, Nathan
  and Talwar, Kunal
author:
- given: Hubert
  family: Eichner
- given: Tomer
  family: Koren
- given: Brendan
  family: Mcmahan
- given: Nathan
  family: Srebro
- given: Kunal
  family: Talwar
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/eichner19a/eichner19a-supp.pdf
- label: Code
  link: https://github.com/tensorflow/federated/tree/master/tensorflow_federated/python/research/semi_cyclic_sgd
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
