---
title: 'Jumpout : Improved Dropout for Deep Neural Networks with ReLUs'
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/wang19q/wang19q.pdf
url: http://proceedings.mlr.press/v97/wang19q.html
abstract: 'We discuss three novel insights about dropout for DNNs with ReLUs: 1) dropout
  encourages each local linear piece of a DNN to be trained on data points from nearby
  regions; 2) the same dropout rate results in different (effective) deactivation
  rates for layers with different portions of ReLU-deactivated neurons; and 3) the
  rescaling factor of dropout causes a normalization inconsistency between training
  and test when used together with batch normalization. The above leads to three simple
  but nontrivial modifications resulting in our method “jumpout.” Jumpout samples
  the dropout rate from a monotone decreasing distribution (e.g., the right half of
  a Gaussian), so each local linear piece is trained, with high probability, to work
  better for data points from nearby than more distant regions. Jumpout moreover adaptively
  normalizes the dropout rate at each layer and every training batch, so the effective
  deactivation rate on the activated neurons is kept the same. Furthermore, it rescales
  the outputs for a better trade-off that keeps both the variance and mean of neurons
  more consistent between training and test phases, thereby mitigating the incompatibility
  between dropout and batch normalization. Jumpout significantly improves the performance
  of different neural nets on CIFAR10, CIFAR100, Fashion-MNIST, STL10, SVHN, ImageNet-1k,
  etc., while introducing negligible additional memory and computation costs.'
layout: inproceedings
id: wang19q
tex_title: 'Jumpout : Improved Dropout for Deep Neural Networks with {R}e{LU}s'
firstpage: 6668
lastpage: 6676
page: 6668-6676
order: 6668
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Wang, Shengjie and Zhou, Tianyi and Bilmes, Jeff
author:
- given: Shengjie
  family: Wang
- given: Tianyi
  family: Zhou
- given: Jeff
  family: Bilmes
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
