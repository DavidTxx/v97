---
title: Alternating Minimizations Converge to Second-Order Optimal Solutions
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/li19n/li19n.pdf
url: http://proceedings.mlr.press/v97/li19n.html
abstract: This work studies the second-order convergence for both standard alternating
  minimization and proximal alternating minimization. We show that under mild assumptions
  on the (nonconvex) objective function, both algorithms avoid strict saddles almost
  surely from random initialization. Together with known first-order convergence results,
  this implies both algorithms converge to a second-order stationary point. This solves
  an open problem for the second-order convergence of alternating minimization algorithms
  that have been widely used in practice to solve large-scale nonconvex problems due
  to their simple implementation, fast convergence, and superb empirical performance.
layout: inproceedings
id: li19n
tex_title: Alternating Minimizations Converge to Second-Order Optimal Solutions
firstpage: 3935
lastpage: 3943
page: 3935-3943
order: 3935
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Li, Qiuwei and Zhu, Zhihui and Tang, Gongguo
author:
- given: Qiuwei
  family: Li
- given: Zhihui
  family: Zhu
- given: Gongguo
  family: Tang
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
