---
title: Adversarial Examples Are a Natural Consequence of Test Error in Noise
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/gilmer19a/gilmer19a.pdf
url: http://proceedings.mlr.press/v97/gilmer19a.html
abstract: 'Over the last few years, the phenomenon of <em>adversarial examples</em>
  — maliciously constructed inputs that fool trained machine learning models — has
  captured the attention of the research community, especially when restricted to
  small modifications of a correctly handled input. Less surprisingly, image classifiers
  also lack human-level performance on randomly corrupted images, such as images with
  additive Gaussian noise. In this paper we provide both empirical and theoretical
  evidence that these are two manifestations of the same underlying phenomenon, and
  therefore the adversarial robustness and corruption robustness research programs
  are closely related. This suggests that improving adversarial robustness should
  go hand in hand with improving performance in the presence of more general and realistic
  image corruptions. This yields a computationally tractable evaluation metric for
  defenses to consider: test error in noisy image distributions.'
layout: inproceedings
id: gilmer19a
tex_title: Adversarial Examples Are a Natural Consequence of Test Error in Noise
firstpage: 2280
lastpage: 2289
page: 2280-2289
order: 2280
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Gilmer, Justin and Ford, Nicolas and Carlini, Nicholas and Cubuk, Ekin
author:
- given: Justin
  family: Gilmer
- given: Nicolas
  family: Ford
- given: Nicholas
  family: Carlini
- given: Ekin
  family: Cubuk
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/gilmer19a/gilmer19a-supp.pdf
- label: Code
  link: https://github.com/nicf/corruption-robustness
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
