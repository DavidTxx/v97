---
title: Characterization of Convex Objective Functions and Optimal Expected Convergence
  Rates for SGD
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/van-dijk19a/van-dijk19a.pdf
url: http://proceedings.mlr.press/v97/vandijk19a.html
abstract: We study Stochastic Gradient Descent (SGD) with diminishing step sizes for
  convex objective functions. We introduce a definitional framework and theory that
  defines and characterizes a core property, called curvature, of convex objective
  functions. In terms of curvature we can derive a new inequality that can be used
  to compute an optimal sequence of diminishing step sizes by solving a differential
  equation. Our exact solutions confirm known results in literature and allows us
  to fully characterize a new regularizer with its corresponding expected convergence
  rates.
layout: inproceedings
id: van-dijk19a
tex_title: Characterization of Convex Objective Functions and Optimal Expected Convergence
  Rates for {SGD}
firstpage: 6392
lastpage: 6400
page: 6392-6400
order: 6392
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Van Dijk, Marten and Nguyen, Lam and Nguyen, Phuong Ha and Phan, Dzung
author:
- given: Marten
  family: Van Dijk
- given: Lam
  family: Nguyen
- given: Phuong Ha
  family: Nguyen
- given: Dzung
  family: Phan
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/van-dijk19a/van-dijk19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
