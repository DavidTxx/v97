---
title: 'AdaGrad stepsizes: sharp convergence over nonconvex landscapes'
booktitle: Proceedings of the 36th International Conference on Machine Learning
year: '2019'
volume: '97'
address: 
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v97/ward19a/ward19a.pdf
url: http://proceedings.mlr.press/v97/ward19a.html
abstract: Adaptive gradient methods such as AdaGrad and its variants update the stepsize
  in stochastic gradient descent on the fly according to the gradients received along
  the way; such methods have gained widespread use in large-scale optimization for
  their ability to converge robustly, without the need to fine-tune parameters such
  as the stepsize schedule. Yet, the theoretical guarantees to date for AdaGrad are
  for online and convex optimization. We bridge this gap by providing strong theoretical
  guarantees for the convergence of AdaGrad over smooth, nonconvex landscapes. We
  show that the norm version of AdaGrad (AdaGrad-Norm) converges to a stationary point
  at the $\mathcal{O}(\log(N)/\sqrt{N})$ rate in the stochastic setting, and at the
  optimal $\mathcal{O}(1/N)$ rate in the batch (non-stochastic) setting – in this
  sense, our convergence guarantees are “sharp”. In particular, both our theoretical
  results and extensive numerical experiments imply that AdaGrad-Norm is robust to
  the <em>unknown Lipschitz constant and level of stochastic noise on the gradient</em>.
layout: inproceedings
id: ward19a
tex_title: "{A}da{G}rad stepsizes: sharp convergence over nonconvex landscapes"
firstpage: 6677
lastpage: 6686
page: 6677-6686
order: 6677
cycles: false
bibtex_editor: Chaudhuri, Kamalika and Salakhutdinov, Ruslan
editor:
- given: Kamalika
  family: Chaudhuri
- given: Ruslan
  family: Salakhutdinov
bibtex_author: Ward, Rachel and Wu, Xiaoxia and Bottou, Leon
author:
- given: Rachel
  family: Ward
- given: Xiaoxia
  family: Wu
- given: Leon
  family: Bottou
date: 2019-05-24
container-title: Proceedings of the 36th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 5
  - 24
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v97/ward19a/ward19a-supp.pdf
- label: Code
  link: https://github.com/xwuShirley/pytorch/blob/master/torch/optim/adagradnorm.py
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
